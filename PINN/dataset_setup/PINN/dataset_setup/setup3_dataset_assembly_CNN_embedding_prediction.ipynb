{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x1. read in dyndb spreadsheet\n",
    "x2. read in static database\n",
    "x3. assign PNs to dyndb\n",
    "\n",
    "4. instantiate and load weights for multi-param [3D]CNN\n",
    "[4a. figure out how to get embedding vector... look @ your '9_test_troubleshoot_experiment/vizualize_3DCNN_filters.ipynb']\n",
    "5. load, run each topo array through 3DCNN --> extract predicted properties and feature vector\n",
    "    ???? predicted properties in a single vector in a single column, or separate columns?... probably separate, so I can pick and choose...\n",
    "\n",
    "6... Profit? I think that's it...\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyndb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyndb.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbpath     = '/home/mgolub4/DLproj/MLTO_2024/3_Dynamic_PINN_RNN'\n",
    "voxel_path = '/home/mgolub4/DLproj/MLTO_2024/0_data/voxel_arrays_npy_by_partno'\n",
    "\n",
    "# dbpath = os.path.join(nbpath, 'dyn_data', 'dynamic_static_database_scaled_DEC23_constit_eqn_fit_params.csv')\n",
    "dbpath = os.path.join(nbpath, 'dyn_data', 'dynamic_static_database_scaled_APR24_constit_eqn_fit_params.csv')\n",
    "\n",
    "\n",
    "dyndb = pd.read_csv(dbpath)\n",
    "\n",
    "stress_ser_path = os.path.join(nbpath, 'dyn_data/stress_series_data')\n",
    "\n",
    "csvs = [p for p in sorted(os.listdir(stress_ser_path)) if p.endswith('untrunc.csv')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Part Number column to \n",
    "dyndb['full PN'] = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyndb_csvs = (dyndb.dyn_file_name_original + '_processed_untrunc').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statdb = pd.read_csv('/home/mgolub4/DLproj/MLTO_2024/0_data/data_3phys_w_dyn_topos_scaled_PNs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dyndb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "\n",
    "cell_type = dyndb.loc[i, 'cell_type']\n",
    "volfrac = dyndb.loc[i, 'volFrac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statdb[(statdb.cell_type == cell_type) & (statdb.volFrac == volfrac)]['full PN'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dyndb.index:\n",
    "    cell_type = dyndb.loc[i, 'cell_type']\n",
    "    volfrac = dyndb.loc[i, 'volFrac']\n",
    "\n",
    "    partnum = statdb[(statdb.cell_type == cell_type) & (statdb.volFrac == volfrac)]['full PN'].values[0]\n",
    "\n",
    "    dyndb.loc[i, 'full PN'] = partnum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dyndb.full_PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from v4_multimod_attn_8mlp_wRelu_longer_featvec import Linear_Feature_Attention, CNN3D_multimod_attn_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dir = '/home/mgolub4/DLproj/MLTO_2024/3_Dynamic_PINN_RNN/dataset_setup/CP_run18_sd17_augm_vf0p98_v4_multimod_attn_8mlp_wRelu_longer_featvec_28par_allphys.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['volFrac', \n",
    "        'CH_11 scaled', 'CH_22 scaled', 'CH_33 scaled', 'CH_44 scaled', 'CH_55 scaled', 'CH_66 scaled',\n",
    "        'CH_12 scaled', 'CH_13 scaled','CH_23 scaled',\n",
    "        'EH_11 scaled', 'EH_22 scaled', 'EH_33 scaled',\n",
    "        'GH_23 scaled', 'GH_13 scaled', 'GH_12 scaled', \n",
    "        'vH_12 scaled', 'vH_13 scaled', 'vH_23 scaled', 'vH_21 scaled', 'vH_31 scaled','vH_32 scaled',\n",
    "        'KH_11 scaled', 'KH_22 scaled', 'KH_33 scaled', \n",
    "        'kappaH_11 scaled', 'kappaH_22 scaled', 'kappaH_33 scaled']\n",
    "\n",
    "params_segmented = [['volFrac',], \n",
    "                    ['CH_11 scaled', 'CH_22 scaled', 'CH_33 scaled', 'CH_44 scaled', 'CH_55 scaled', 'CH_66 scaled',],\n",
    "                    ['CH_12 scaled', 'CH_13 scaled','CH_23 scaled',],\n",
    "                    ['EH_11 scaled', 'EH_22 scaled', 'EH_33 scaled',],\n",
    "                    ['GH_23 scaled', 'GH_13 scaled', 'GH_12 scaled',],\n",
    "                    ['vH_12 scaled', 'vH_13 scaled', 'vH_23 scaled', 'vH_21 scaled', 'vH_31 scaled','vH_32 scaled',],\n",
    "                    ['KH_11 scaled', 'KH_22 scaled', 'KH_33 scaled',],\n",
    "                    ['kappaH_11 scaled', 'kappaH_22 scaled', 'kappaH_33 scaled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN3D_multimod_attn_v4(params_segmented).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(cp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_module_weights = OrderedDict()\n",
    "\n",
    "for k, v in weights.items():\n",
    "    name = k[7:] # remove 'module.'\n",
    "    non_module_weights[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.load_state_dict(non_module_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyndb['conv_feat_vec'] = pd.Series()\n",
    "pred_param_cols = []\n",
    "for par in params:\n",
    "    colname = f'pred {par}'\n",
    "    dyndb[colname] = pd.Series()\n",
    "    pred_param_cols.append(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partnum = dyndb.loc[0, 'full PN']\n",
    "arrpath = os.path.join(voxel_path, f'{partnum}.npy')\n",
    "arr = np.expand_dims(np.load(arrpath), axis=(0,1)).astype(np.float32)\n",
    "arr_tensor = torch.from_numpy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tensor = arr_tensor.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_vector(in_tensor, cnn):\n",
    "    in_tensor = in_tensor.to(device)\n",
    "    for i in range(len(cnn.convolutions)):\n",
    "        layer_out = cnn.convolutions[i](in_tensor)\n",
    "\n",
    "        layer = cnn.convolutions[i]\n",
    "\n",
    "        in_tensor = layer_out\n",
    "\n",
    "    in_tensor = in_tensor.detach().cpu().numpy()\n",
    "        \n",
    "    in_tensor = np.squeeze(in_tensor, axis=(2,3,4))\n",
    "    return in_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrt = embed_vector(arr_tensor, cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn(arr_tensor.to(device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featmap_folder = '/home/mgolub4/DLproj/MLTO_2024/3_Dynamic_PINN_RNN/dyn_data/voxel_embedding_feature_maps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dyndb.index[:]:\n",
    "    partnum = dyndb.loc[i, 'full PN']\n",
    "    arrpath = os.path.join(voxel_path, f'{partnum}.npy')\n",
    "    arr = np.expand_dims(np.load(arrpath), axis=(0,1)).astype(np.float32)\n",
    "    arr_tensor = torch.from_numpy(arr)\n",
    "\n",
    "    conv_feature_vector = embed_vector(arr_tensor, cnn)\n",
    "\n",
    "    emb_vec_partnum = partnum + '_emb_vec'\n",
    "    emb_vec_fpath = os.path.join(featmap_folder, emb_vec_partnum)\n",
    "    np.save(emb_vec_fpath, conv_feature_vector)\n",
    "    \n",
    "    param_vec = cnn(arr_tensor.to(device)).detach().cpu().numpy()\n",
    "\n",
    "    dyndb.loc[i, 'conv_feat_vec'] = emb_vec_partnum\n",
    "\n",
    "    for j, col in enumerate(pred_param_cols):\n",
    "        dyndb.loc[i, col] = param_vec[0,j]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyndb.to_csv('/home/mgolub4/DLproj/MLTO_2024/3_Dynamic_PINN_RNN/dyn_data/dyn_stat_database_PINN_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

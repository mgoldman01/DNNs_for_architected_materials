{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all material properties using pre-trained convolutional neural network\n",
    "\n",
    "This notebook loads the included pre-trained convolutional neural network for predicting all non-zero material properties from the following physics:\n",
    "\n",
    "<u>__Mechanics__</u>:\n",
    "\n",
    "* <u>Stiffness Matrix</u>: $C_{11}^{H},\\ C_{22}^{H},\\ C_{33}^{H},\\ C_{44}^{H},\\ C_{55}^{H},\\ C_{66}^{H},\\ C_{12}^{H},\\ C_{13}^{H},\\ C_{23}^{H}$ \n",
    "\n",
    "* <u>Young's Modulus</u>: $E_{11}^{H},\\ E_{22}^{H},\\ E_{33}^{H}$\n",
    "\n",
    "* <u>Shear Modulus</u>: $G_{23}^{H},\\ G_{13}^{H},\\ G_{12}^{H}$\n",
    "\n",
    "* <u>Poisson's Ratio</u>:\t$\\nu_{12}^{H},\\nu_{13}^{H},\\nu_{23}^{H},\\nu_{21}^{H},\\nu_{31}^{H},\\nu_{32}^{H}$\t\n",
    "\n",
    "<u>__Fluid Permeability__</u>: $K_{11}^{H},\\ K_{22}^{H},\\ K_{33}^{H}$\n",
    "\n",
    "<u>__Thermal Conductivity__</u>: $\\kappa_{11}^{H},\\ \\kappa_{22}^{H},\\ \\kappa_{33}^{H}$\n",
    "\n",
    "\n",
    "\n",
    "<u>Input</u>: A 64x64x64 voxel mesh of an architected material unit cell\n",
    "\n",
    "<u>Workflow</u>: \n",
    "1. Load in selected voxel mesh and trained Convolutional Neural Network\n",
    "2. Model performs inference on input mesh\n",
    "\n",
    "<u>Output</u>:\n",
    "Predicted material property vector.\n",
    "\n",
    "__NOTE 1__: The material property vector's elements are in the order above\n",
    "\n",
    "__NOTE 2__: Included model predicts values that have been min-max scaled. Code to un-scale data is included here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  __Setup - import packages, define properties and paths__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# PyTorch deep learning library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "# Will automatically select GPU acceleration if hardware is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Custom classes and functions\n",
    "from ML_workflow_utils_v3.Dataset_Preprocessor import Dataset_Preprocessor as DataP\n",
    "from ML_workflow_utils_v3.Voxel_Mesh_Utils import Plot_Array\n",
    "from ML_workflow_utils_v3.Misc_Utils import unscale\n",
    "from ML_workflow_utils_v3.Model_Weights_Util import convert_state_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For setting the directory references for the entire package\n",
    "from ML_workflow_utils_v3.PackageDirectories import PackageDirectories as PD   \n",
    "\n",
    "# This code automatically sets the rootpath as the directory the entire package is contained in, which is then called to initialize the PackageDirectories class below\n",
    "import os\n",
    "# check current path if desired\n",
    "# currentpath = os.getcwd()\n",
    "# print(currentpath)\n",
    "\n",
    "os.chdir('../../../')\n",
    "rootpath = os.getcwd()\n",
    "# print(rootpath)\n",
    "\n",
    "# Alternately, rootpath can be set manually\n",
    "# rootpath = 'filepath/containing/entire/ML_package/'\n",
    "\n",
    "directory = PD(rootpath = rootpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material Properties and CNN configuration\n",
    "\n",
    "#### __Note__: `matprops` and `matprops_by_module` are configured for the pre-trained model that comes with this package. If running inference on a new model trained in notebook 1_1, change these variables to reflect the material properties and their groupings used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Material Properties #####\n",
    "matprops = ['volFrac', \n",
    "         'CH_11 scaled', 'CH_22 scaled', 'CH_33 scaled', 'CH_44 scaled', 'CH_55 scaled', 'CH_66 scaled',\n",
    "         'CH_12 scaled', 'CH_13 scaled','CH_23 scaled',\n",
    "         'EH_11 scaled', 'EH_22 scaled', 'EH_33 scaled',\n",
    "         'GH_23 scaled', 'GH_13 scaled', 'GH_12 scaled', \n",
    "         'vH_12 scaled', 'vH_13 scaled', 'vH_23 scaled', 'vH_21 scaled', 'vH_31 scaled','vH_32 scaled',\n",
    "         'KH_11 scaled', 'KH_22 scaled', 'KH_33 scaled', \n",
    "         'kappaH_11 scaled', 'kappaH_22 scaled', 'kappaH_33 scaled']\n",
    "\n",
    "matprops_by_module = [['volFrac',], \n",
    "                      ['CH_11 scaled', 'CH_22 scaled', 'CH_33 scaled', 'CH_44 scaled', 'CH_55 scaled', 'CH_66 scaled',],\n",
    "                      ['CH_12 scaled', 'CH_13 scaled','CH_23 scaled',],\n",
    "                      ['EH_11 scaled', 'EH_22 scaled', 'EH_33 scaled',],\n",
    "                      ['GH_23 scaled', 'GH_13 scaled', 'GH_12 scaled',],\n",
    "                      ['vH_12 scaled', 'vH_13 scaled', 'vH_23 scaled', 'vH_21 scaled', 'vH_31 scaled','vH_32 scaled',],\n",
    "                      ['KH_11 scaled', 'KH_22 scaled', 'KH_33 scaled',],\n",
    "                      ['kappaH_11 scaled', 'kappaH_22 scaled', 'kappaH_33 scaled']]\n",
    "\n",
    "num_props = len(matprops) # for determining the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for saved weights of trained parameter prediction neural network \n",
    "cnn_filepath = directory.convnetpath\n",
    "cnn_cp = 'Mat_prop_CNN3D_all_props_model_weights.pth'\n",
    "\n",
    "cp_path = os.path.join(cnn_filepath, cnn_cp)\n",
    "\n",
    "# If loading a model trained in notebook 1_1, use this code:\n",
    "# cnn_filepath = os.path.join(directory.nb_1_1_path, 'model_CPs')\n",
    "# cnn_cp = 'PLACEHOLDER_model_weights.pth' -- change to the actual name of the CP\n",
    "\n",
    "# cp_path = os.path.join(cnn_filepath, cnn_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model architecture\n",
    "\n",
    "from ML_workflow_utils_v3.CNN_MatProp_ConvNet_AllProperties import MatProp_CNN3D_all_matprops\n",
    "cnn = MatProp_CNN3D_all_matprops(matprops_by_module).to(device)\n",
    "\n",
    "# If using a newly trained model, load as follows:\n",
    "# from ML_workflow_utils_v3.CNN_Property_Predictor_Multimodule import MatProp_CNN3D_varmod\n",
    "# cnn = MatProp_CNN3D_varmod(matprops_by_module).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This command loads the trained model's weights\n",
    "\n",
    "The included pre-trained model weights were produced using a multi-GPU training setup, therefore the key of each layer contains \"module.\", \n",
    "which is how torch.nn.DataParallel() creates state dictionaries. The call of \"convert_state_dict\"\n",
    "If using more than one GPU for topology production, set \"convert_weight_keys_to\" to 'parallel'\n",
    "\"\"\"\n",
    "\n",
    "convert_weight_keys_to = 'non-parallel'\n",
    "\n",
    "model_weights = convert_state_dict(cp_path, convert_to = convert_weight_keys_to)\n",
    "\n",
    "\n",
    "\n",
    "cnn.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load from the database, utilize Pandas dataframe filtering functions to select by topology family, unit cell type, or any other characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a 64x64x64 mesh array of a unit cell\n",
    "\n",
    "db_csv_name = 'topology_multiphysics_database_by_partno.csv'\n",
    "dbpath = os.path.join(directory.source_data_path, db_csv_name)\n",
    "db = pd.read_csv(dbpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print only the columns useful for selecting a topology for property prediction -- topology family, unit cell type, volume fraction, and full part number\n",
    "sel_cols = ['topology_family', 'cell_type', 'volFrac', 'full PN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints selected values. Change cell_type to a different topology to display the part numbers and pick a different unit for material property prediction\n",
    "cell_type = 'gyroid'\n",
    "print(db[db.cell_type == cell_type][sel_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = '05-2502-0009'#00-0000-000'\n",
    "pn_file = f'{pn}.npz'\n",
    "\n",
    "data_folder = directory.voxeltopo_path\n",
    "\n",
    "pn_path = os.path.join(data_folder, pn_file)\n",
    "\n",
    "array = np.load(pn_path)['arr_0'] # .npz file loads as a dict-like object, this key accesses the binary array that represents the voxel mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the array in 3 dimensions if desired\n",
    "Plot_Array(array, export_png=False, binary=True, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictionn\n",
    "# expand_dims is required because neural network accepts array of size (batch_size, 1, 68, 68 68). batch_size=1 for predicting the parameters of a single array\n",
    "array = array.astype(np.float32)\n",
    "target_tensor = torch.tensor(np.expand_dims(array, axis=(0,1)))\n",
    "target_predictions = cnn(target_tensor.to(dtype=torch.float32).to(device)).cpu().detach().numpy().T\n",
    "target_predictions = np.squeeze(target_predictions, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print predictions\n",
    "for i in range(len(matprops)):\n",
    "    print(f'Predicted \\\"{matprops[i]}\\\"  = {target_predictions[i]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-scale the predictions and print\n",
    "unscaled_values = []\n",
    "for i in range(len(matprops)):\n",
    "    par = matprops[i].split(' ')[0]\n",
    "    unscaled = unscale(db, par, target_predictions[i])\n",
    "    unscaled_values.append(unscaled)\n",
    "    print(f'{par}')\n",
    "    print(f'Predicted (as scaled): {target_predictions[i]:.4f}')\n",
    "    print(f'Un-scaled: \\t       {unscaled:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21d719bb0196cef14b3a1b5c98d44dc5c6eb472f8a40fea5f6e94c35d0d21b95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
